:hardbreaks:
= 쏘카 데이터 그룹 글

== 쏘카 데이터 그룹 - Airflow와 함께한 데이터 환경 구축기(feat. Airflow on Kubernetes) 2021.06.01
지난 3년간 Airflow 구축 및 운영기록

https://tech.socarcorp.kr/data/2021/06/01/data-engineering-with-airflow.html

2018년 부터 2021년 까지 어떻게 Airflow를 구축하고 운영했는지

2018 데이터 그룹 설립
기존 쏘카 테크 조직들은 Task 스케줄링 도구로 Rundeck을 이용하고 있었음. 데이터 그룹에서도 이 Rundeck을 그대로 사용할지, 아니면 새로운 도구를 도입해볼지 고민. 다음과 같은 요구사항을 염두해 두었음

1. 데이터 파이프라인(ELT 혹은 ETL) 스케줄링 작업과 쏘카 서비스의 스케줄링 작업 분리를 시켜야 함
* 쏘카 서비스와 관련된 스케쥴링 작업은 실제 고객을 대상으로하는 작업이므로, 데이터 파이프라인보다 우선순위가 높음
* 데이터 파이프라인 작업 때문에 쏘카 서비스에 영향을 주어서는 안 됨
2. 데이터 파이프라인을 위한 다양한 기능이 제공되는 도구 원함
* 쏘카는 데이터 웨어하우스로 BigQuery를 사용하고 있었으므로, BigQuery 및 클라우드와 수비게 연동이 가능한 도구면 좋음
3. Workflow 시각화를 잘해주는 도구 원함
* 많은 데이터 파이프라인이 만들어질텐데, 이 파이프라인들이 어떤 테스크를 수행하는지 한 눈에 확인 가능해야 함

기존 Rundeck은 위와 같은 요구사항을 충족시키기엔 부족했기에, 새로운 도구를 도입하기로 결정했음. 결과적으로 당시 데이터 파이프라인 플랫픔오르 많이 쓰이는 Apache Airflow를 사용해보기로 결정했음





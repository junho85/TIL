:hardbreaks:
= 쏘카 데이터 그룹 글

== 쏘카 데이터 그룹 - Airflow와 함께한 데이터 환경 구축기(feat. Airflow on Kubernetes) 2021.06.01
지난 3년간 Airflow 구축 및 운영기록

https://tech.socarcorp.kr/data/2021/06/01/data-engineering-with-airflow.html

2018년 부터 2021년 까지 어떻게 Airflow를 구축하고 운영했는지

2018 데이터 그룹 설립
기존 쏘카 테크 조직들은 Task 스케줄링 도구로 Rundeck을 이용하고 있었음. 데이터 그룹에서도 이 Rundeck을 그대로 사용할지, 아니면 새로운 도구를 도입해볼지 고민. 다음과 같은 요구사항을 염두해 두었음

1. 데이터 파이프라인(ELT 혹은 ETL) 스케줄링 작업과 쏘카 서비스의 스케줄링 작업 분리를 시켜야 함
* 쏘카 서비스와 관련된 스케쥴링 작업은 실제 고객을 대상으로하는 작업이므로, 데이터 파이프라인보다 우선순위가 높음
* 데이터 파이프라인 작업 때문에 쏘카 서비스에 영향을 주어서는 안 됨
2. 데이터 파이프라인을 위한 다양한 기능이 제공되는 도구 원함
* 쏘카는 데이터 웨어하우스로 BigQuery를 사용하고 있었으므로, BigQuery 및 클라우드와 수비게 연동이 가능한 도구면 좋음
3. Workflow 시각화를 잘해주는 도구 원함
* 많은 데이터 파이프라인이 만들어질텐데, 이 파이프라인들이 어떤 테스크를 수행하는지 한 눈에 확인 가능해야 함

기존 Rundeck은 위와 같은 요구사항을 충족시키기엔 부족했기에, 새로운 도구를 도입하기로 결정했음. 결과적으로 당시 데이터 파이프라인 플랫픔오르 많이 쓰이는 Apache Airflow를 사용해보기로 결정했음

태동기 - Google Cloud Composer

데이터 그룹이 생긴 태동기에는 데이터 엔지니어가 없었음. 데이터 분석가들이 직접 데이터 파이프라인을 만들어야 했음
기술적인 이슈보다 당장 분석에 필요한 파이프라인을 만드는 것이 가장 높은 우선순위였음. 따라서 직접 구축 및 관리가 필요 없는 Google Cloud의 Cloud Composer를 사용하게 되었음

Cloud Composer는 Google Cloud에서 제공하는 Managed Airflow 서비스. 참고로 AWS에도 Managed Airflow(MWAA)가 존재하지만, 그 당시엔 구글 클라우드의 Cloud Composer가 유일했음. 또한 쏘카에선 데이터 웨어하우스를 구글 클라우드의 BigQuery로 사용했기 때문에 같은 구글 클라우드 서비스가 꽤 괜찮은 이점을 줄 거라 생각했음.

Cloud Composer는 정말 간단하게 사용할 수 있음. Airflow의 DAG 파일을 Cloud Storag에 업로드해서 사용함. Cloud Storag에 Airflow DAG 파일을 업로드하면 Cloud Composer에서 해당 파일을 읽어 작업을 실행함. 사용자 입장에서 Airflow 구성 요소에 대해 크게 신경 쓸 필요가 없이 DAG 파일만 잘 만들면 됨.

그러나 Composer는 종종 알 수 없는 에러를 발생시켰음. 당시 Airflow의 버전은 1.10.3로 오픈소스 자체에도 버그가 존재했음. 오류가 생겼을 때 로그를 직접 제대로 볼 수 없는 것이 1.10.3 버전의 가장 큰 문제였음.
Composer의 안정성 문제와 로그와 관련된 이슈로 Composer를 계속 사용해야 하는가에 대한 고민이 시작되었음.

초창기 - Google Computer Engine + Docker Compose

데이터 그룹이 생긴 몇 달 뒤 데이터 엔지니어분들이 데이터 그룹에 합류하게 되었고, 자체 데이터 엔지니어링 팀이 탄생했음. 이제 데이터 엔지니어링팀에서 데이터 파이프라인 구축과 인프라 운영을 담당하게 되었고, 이전보다 좀 더 체계적인 데이터 분석 환경을 구축해볼 수 있게 되었음. 이제 Cloud Composer를 벗어나 데이터 엔지니어링 팀에서 Airflow를 직접 구축하고 운영하기로 하였음.

고려 사항
* 빠르고 간단하게 배포할 수 있어야 함
* 데이터 그룹의 누구나(데이터 분석가/데이터 사이언티스트, 데이터 엔지니어) 쉽게 DAG 작성이 가능해야 함.
* 운영이 수월해야 함

데이터 엔지니어링 팀과 데이터 그룹이 크지 않기 때문에 간단하며 신속하고 유연하게 움직일 수 있는 방식을 고려했음

의사 결정
고민 끝에 선택한 배포 방법은 Google Compute Engine 위에 Docker Compose로 Airflow의 각 컴포넌트 (Webserver, Scheduler 등)를 직접 Docker 컨테이너로 띄우는 방법. Github에 있는 pucket/docker-airflow 이미지를 이용하면 이를 쉽게 구현할 수 있었음.

https://github.com/puckel/docker-airflow

또한 분석 팀원들에게 익숙한 Jupyter Notebook을 동일 환경에서 배포하고, Jupyter Notebok을 통해 Airflow DAG을 수정할 수 있도록 했음

배포 형태
* Google Cloud Platform의 Google Computer Engine 인스턴스를 호스팅 서버로 사용함
* Airflow의 각 컴포넌트인 WebServer, Scheduler, Database, Worker, Redis를 Docker Compose를 통해 각각 컨테이너로 실행함
* Airflow Scheduler는 Celery Executo를 사용함
* Jupyter Notebook을 Docker 컨테이너로 띄운 뒤 Airflwo DAG 폴더에 Volume Mount함

이렇게 하면 Airflow의 각각의 컴포넌트에 대해 통제가 가능해짐 (Docker Container 재시작, 버전 업데이트, 로그 등)
